# Unsupervised Learning Toolkit: K-Means, GMM, CVAE & More

This repository showcases a collection of essential **unsupervised learning algorithms**, implemented using NumPy and PyTorch. Each method is applied to real-world tasks like **image compression**, **dimensionality reduction**, **source separation**, and **conditional image generation**.

---

## üìå Overview

| Method | Description |
|--------|-------------|
| K-Means | Hard clustering used for image compression and color quantization. |
| GMM     | Soft probabilistic clustering using the Expectation-Maximization (EM) algorithm. |
| PCA     | Linear dimensionality reduction via eigen decomposition. |
| ICA     | Blind source separation based on statistical independence. |
| CVAE    | Conditional deep generative modeling using Variational Autoencoder architecture. |

---

## 1Ô∏è‚É£ K-Means Clustering

K-Means partitions input data (e.g. image pixels) into `K` clusters by minimizing intra-cluster variance. It is widely used for **color quantization** and **image compression**.

### üì∑ Result: K-Means Color Quantization

<img src="Images/Kmeans_Result.png" width="700"/>

---

## 2Ô∏è‚É£ Gaussian Mixture Models (GMM)

GMM extends K-Means by modeling each cluster as a Gaussian distribution, learned via the EM algorithm. It performs **soft assignment**, assigning probabilities to each cluster.

### üì∑ Result: GMM-Based Image Compression (K=5)

<img src="Images/GMM_Result.png" width="700"/>

---

## 3Ô∏è‚É£ Principal Component Analysis (PCA)

PCA reduces dimensionality by projecting data onto the top eigenvectors of its covariance matrix. It's especially useful for visualizing high-dimensional datasets like **faces** or **gene expressions**.

### üì∑ Result: PCA Eigenfaces Visualization

<img src="Images/EigenFace.png" width="700"/>

---

## 4Ô∏è‚É£ Independent Component Analysis (ICA)

ICA separates mixed signals into statistically independent components. Often used in **audio signal processing** or **blind source separation**, it differs from PCA by targeting independence rather than uncorrelatedness.

_(Image not included; ICA typically yields 1D signal plots)_

---

## 5Ô∏è‚É£ Conditional Variational Autoencoder (CVAE)

CVAE is a deep generative model that allows you to generate samples **conditioned on a class label**. It is trained on the MNIST dataset to generate digits based on specific labels using the reparameterization trick.

### üì∑ Result: CVAE Digit Generation (0‚Äì9 Grid)

<img src="Images/CAVE_Result.png" width="400"/>

---

## üìÑ License

This repository is created for educational purposes (EECS 545 @ University of Michigan). Not licensed for commercial use.

---


## üß™ Requirements

- Python ‚â• 3.7
- NumPy
- SciPy
- scikit-learn
- PyTorch
- torchvision
- matplotlib
- Jupyter Notebook

To install the dependencies:

```bash
pip install -r requirements.txt
